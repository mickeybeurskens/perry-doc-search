{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1521c61-a06e-44db-abf5-d6c9505ea6b8",
   "metadata": {},
   "source": [
    "# Document Search\n",
    "Set up a vector based document search for multiple file types. As files we use a txt file and pdf files, in this case the 10-k filings of Uber from 2019-2022. The goal is to be able to search through these documents using a search query and return the most relevant parts in the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7e03f1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘doc_data’: File exists\n",
      "--2023-07-09 13:28:31--  https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 2620:100:6021:18::a27d:4112, 162.125.65.18\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|2620:100:6021:18::a27d:4112|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/dl/948jr9cfs7fgj99/UBER.zip [following]\n",
      "--2023-07-09 13:28:31--  https://www.dropbox.com/s/dl/948jr9cfs7fgj99/UBER.zip\n",
      "Reusing existing connection to [www.dropbox.com]:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc797cd666d44857ff92b9c7d7bd.dl.dropboxusercontent.com/cd/0/get/B_ghPjekQq-O3SjX6e0b5mHWAJvLA-A6u0YkV4IaJ7jcX5DrpzVagPgeYqv6c-PRSy47fuaI3K07vmbjK53PPhBYWuJUhDb1ABacxY3QjaVDwayvsXLkoLu9sh6h-NmHUlu_G2vqYcKESFv6KpEjDtI5jRjB7CV2QeW47jokZXDHMw/file?dl=1# [following]\n",
      "--2023-07-09 13:28:32--  https://uc797cd666d44857ff92b9c7d7bd.dl.dropboxusercontent.com/cd/0/get/B_ghPjekQq-O3SjX6e0b5mHWAJvLA-A6u0YkV4IaJ7jcX5DrpzVagPgeYqv6c-PRSy47fuaI3K07vmbjK53PPhBYWuJUhDb1ABacxY3QjaVDwayvsXLkoLu9sh6h-NmHUlu_G2vqYcKESFv6KpEjDtI5jRjB7CV2QeW47jokZXDHMw/file?dl=1\n",
      "Resolving uc797cd666d44857ff92b9c7d7bd.dl.dropboxusercontent.com (uc797cd666d44857ff92b9c7d7bd.dl.dropboxusercontent.com)... 2620:100:6021:15::a27d:410f, 162.125.65.15\n",
      "Connecting to uc797cd666d44857ff92b9c7d7bd.dl.dropboxusercontent.com (uc797cd666d44857ff92b9c7d7bd.dl.dropboxusercontent.com)|2620:100:6021:15::a27d:410f|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1820227 (1.7M) [application/binary]\n",
      "Saving to: ‘doc_data/UBER.zip’\n",
      "\n",
      "doc_data/UBER.zip   100%[===================>]   1.74M  8.36MB/s    in 0.2s    \n",
      "\n",
      "2023-07-09 13:28:33 (8.36 MB/s) - ‘doc_data/UBER.zip’ saved [1820227/1820227]\n",
      "\n",
      "Archive:  doc_data/UBER.zip\n",
      "   creating: doc_data/UBER/\n",
      "  inflating: doc_data/UBER/UBER_2021.html  \n",
      "  inflating: doc_data/__MACOSX/UBER/._UBER_2021.html  \n",
      "  inflating: doc_data/UBER/UBER_2020.html  \n",
      "  inflating: doc_data/__MACOSX/UBER/._UBER_2020.html  \n",
      "  inflating: doc_data/UBER/UBER_2019.html  \n",
      "  inflating: doc_data/__MACOSX/UBER/._UBER_2019.html  \n",
      "  inflating: doc_data/UBER/UBER_2022.html  \n",
      "  inflating: doc_data/__MACOSX/UBER/._UBER_2022.html  \n"
     ]
    }
   ],
   "source": [
    "!mkdir doc_data\n",
    "!wget \"https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\" -O doc_data/UBER.zip\n",
    "!unzip doc_data/UBER.zip -d doc_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63d563d6",
   "metadata": {},
   "source": [
    "First load the documents using the Unstructured library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b8d7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import download_loader, VectorStoreIndex, ServiceContext, StorageContext, load_index_from_storage\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "917fbe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from environment variable\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb04c4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bluegnome/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/bluegnome/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "years = [2022, 2021, 2020, 2019]\n",
    "UnstructuredReader = download_loader(\"UnstructuredReader\", refresh_cache=True)\n",
    "\n",
    "loader = UnstructuredReader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e82a8f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_set = {}\n",
    "all_docs = []\n",
    "for year in years:\n",
    "    year_docs = loader.load_data(file=Path(f'./doc_data/UBER/UBER_{year}.html'), split_documents=False)\n",
    "    # insert year metadata into each year\n",
    "    for d in year_docs:\n",
    "        d.metadata = {\"year\": year}\n",
    "    doc_set[year] = year_docs\n",
    "    all_docs.extend(year_docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab39356e",
   "metadata": {},
   "source": [
    "No that each document is loaded (into a Document pydantic schema defined by llama-index), we can create indices for search. We use vector indices here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78018b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(chunk_size=512)  # Set the embedding model to chunk size 512\n",
    "index_set = {}  # Store the indexes for each document\n",
    "for year in years:\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "    cur_index = VectorStoreIndex.from_documents(\n",
    "        doc_set[year],\n",
    "        service_context=service_context,\n",
    "        storage_context=storage_context,\n",
    "    )\n",
    "    index_set[year] = cur_index\n",
    "    storage_context.persist(persist_dir=f'./storage/{year}') # Save the storage index for future use"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64fb7bbe",
   "metadata": {},
   "source": [
    "Load indices from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "563061bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load indices from disk\n",
    "index_set = {}\n",
    "for year in years:\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=f'./storage/{year}')\n",
    "    cur_index = load_index_from_storage(storage_context=storage_context)\n",
    "    index_set[year] = cur_index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d98dc25",
   "metadata": {},
   "source": [
    "# Graph Composition For Question Answering\n",
    "We might want to ask questions on the entire set of documents, in addition to the individual documents. We compose a \"graph\", being a list index consisting of the vector indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "879d98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ListIndex, LLMPredictor, ServiceContext, load_graph_from_storage\n",
    "from langchain import OpenAI\n",
    "from llama_index.indices.composability import ComposableGraph\n",
    "\n",
    "# describe each index to help traversal of composed graph\n",
    "index_summaries = [f\"UBER 10-k Filing for {year} fiscal year\" for year in years]\n",
    "\n",
    "# define an LLMPredictor set number of output tokens\n",
    "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, max_tokens=512))\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
    "storage_context = StorageContext.from_defaults()\n",
    "\n",
    "# define a list index over the vector indices\n",
    "# allows us to synthesize information across each index\n",
    "graph = ComposableGraph.from_indices(\n",
    "    ListIndex,\n",
    "    [index_set[y] for y in years], \n",
    "    index_summaries=index_summaries,\n",
    "    service_context=service_context,\n",
    "    storage_context = storage_context,\n",
    ")\n",
    "root_id = graph.root_id\n",
    "\n",
    "\n",
    "# [optional] save to disk\n",
    "storage_context.persist(persist_dir=f'./storage/root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f68a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [optional] load from disk, so you don't need to build graph from scratch\n",
    "graph = load_graph_from_storage(\n",
    "    root_id=root_id, \n",
    "    service_context=service_context,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cfff40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
